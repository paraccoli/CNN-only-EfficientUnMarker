# CNN-only EfficientUnMarker

**[æ—¥æœ¬èªè§£èª¬ / Japanese Explanation]** | [English](#english)

---

## æ—¥æœ¬èªè§£èª¬

### ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ä½•ã‚’ã™ã‚‹ã‚‚ã®ï¼Ÿ

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€**ç”»åƒã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸå¯è¦–ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯ï¼ˆé€ã‹ã—ï¼‰ã‚’è‡ªå‹•çš„ã«é™¤å»ã™ã‚‹**ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã™ã€‚  
CNNï¼ˆç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡ºå™¨ï¼ˆMobileNetV3ï¼‰ã ã‘ã‚’ä½¿ã£ãŸã€é«˜é€Ÿãƒ»è»½é‡ãƒ»å®Ÿç”¨çš„ãªå®Ÿè£…ã§ã™ã€‚

> **ä¾‹:** ã€ŒGetty Imagesã€ã€ŒSAMPLEã€ãªã©ã®é€ã‹ã—ãŒå…¥ã£ãŸç”»åƒã‹ã‚‰ã€ãã®é€ã‹ã—ã‚’å–ã‚Šé™¤ãã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

---

### å‡¦ç†ã®å…¨ä½“åƒï¼ˆ3ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‰

```
å…¥åŠ›ç”»åƒï¼ˆé€ã‹ã—å…¥ã‚Šï¼‰
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: å‘¨æ³¢æ•°è§£æ                â”‚
â”‚  torch.fft ã§å‘¨æ³¢æ•°ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’åˆ†æ  â”‚
â”‚  â†’ æ”»æ’ƒã™ã¹ãå‘¨æ³¢æ•°å¸¯åŸŸãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ å‘¨æ³¢æ•°å¸¯åŸŸãƒã‚¹ã‚¯
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«æ”»æ’ƒ         â”‚
â”‚  256Ã—256 ã§ç²—æœ€é©åŒ–                 â”‚
â”‚  â†’ å…ƒã®è§£åƒåº¦ã«ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ«        â”‚
â”‚  â†’ é«˜è§£åƒåº¦ã§ç²¾å¯†æœ€é©åŒ–             â”‚
â”‚  â€» æ—©æœŸåœæ­¢ãƒ»PSNR ã‚¬ãƒ¼ãƒ‰ä»˜ã        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ æ”»æ’ƒæ¸ˆã¿ç”»åƒ
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: å“è³ªæ”¹å–„ï¼ˆä»»æ„ãƒ»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç„¡åŠ¹ï¼‰â”‚
â”‚  ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ã§       â”‚
â”‚  ãƒã‚¤ã‚ºã‚’å¹³æ»‘åŒ–                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        å‡ºåŠ›ç”»åƒï¼ˆé€ã‹ã—é™¤å»æ¸ˆã¿ï¼‰
```

---

### å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è©³ç´°èª¬æ˜

#### ğŸ” ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯æ¤œå‡ºå™¨ï¼ˆ`core/detection.py`ï¼‰

é€ã‹ã—ãŒã€Œã¾ã æ®‹ã£ã¦ã„ã‚‹ã‹ã€ã‚’åˆ¤å®šã™ã‚‹CNNãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚æ”»æ’ƒãƒ«ãƒ¼ãƒ—ã®çµ‚äº†æ¡ä»¶ã¨ã—ã¦ä½¿ã„ã¾ã™ã€‚

| ã‚¯ãƒ©ã‚¹å | ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|---|---|---|
| `QuickDetector` | MobileNetV3-Small | è»½é‡ãƒ»é«˜é€Ÿã€‚ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å‡ºåŠ›ã§ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¿”ã™ |
| `DeepDetector` | DenseNet-121 | é«˜ç²¾åº¦ã€‚ä¸ç¢ºå®Ÿãªå ´åˆã«ã®ã¿å‘¼ã°ã‚Œã‚‹ |
| `DualBranchDetector` | MobileNetV3 + DenseNet | ä¿¡é ¼åº¦ãŒæ›–æ˜§ãªå ´åˆã®ã¿ DenseNet ã‚’ä½µç”¨ã™ã‚‹ã€Œé©å¿œãƒ¢ãƒ¼ãƒ‰ã€ |
| `WatermarkDetector` | ä¸Šè¨˜ã®ãƒ©ãƒƒãƒ‘ãƒ¼ | `mode='quick'` / `'deep'` / `'adaptive'` ã‚’åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ |

**å‹•ä½œãƒ•ãƒ­ãƒ¼ï¼ˆadaptive ãƒ¢ãƒ¼ãƒ‰ï¼‰ï¼š**
```
MobileNetV3 ã§ã‚¹ã‚³ã‚¢ç®—å‡º
    â”œâ”€ ã‚¹ã‚³ã‚¢ãŒæ˜ç¢ºï¼ˆ< 0.3 ã¾ãŸã¯ > 0.7ï¼‰â†’ ãã®ã¾ã¾ä½¿ç”¨
    â””â”€ ä¸ç¢ºå®Ÿï¼ˆ0.3 ã€œ 0.7ï¼‰â†’ DenseNet ã‚‚ä½¿ã£ã¦é‡ã¿ä»˜ãå¹³å‡
        quick_weight=0.6, deep_weight=0.4
```

---

#### ğŸ“Š Stage 1: å‘¨æ³¢æ•°è§£æï¼ˆ`core/stage1_frequency.py`ï¼‰

ç”»åƒã®ã©ã®å‘¨æ³¢æ•°å¸¯åŸŸã«é€ã‹ã—ãŒå¤šãå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’äºˆæ¸¬ã—ã€æ”»æ’ƒã®å„ªå…ˆå¸¯åŸŸã‚’æ±ºå®šã—ã¾ã™ã€‚

**å‡¦ç†ã®æµã‚Œï¼š**
1. `torch.fft.rfft2` ã§ç”»åƒã‚’å‘¨æ³¢æ•°é ˜åŸŸã«å¤‰æ›
2. 8ã¤ã®å‘¨æ³¢æ•°å¸¯åŸŸã”ã¨ã«ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»åˆ†æ•£ã‚’è¨ˆç®—
3. MobileNetV3 ã®ç”»åƒç‰¹å¾´é‡ã¨å‘¨æ³¢æ•°ç‰¹å¾´é‡ã‚’çµåˆ
4. å…¨çµåˆå±¤ã§å„å¸¯åŸŸã®ã€Œæ”»æ’ƒå„ªå…ˆåº¦ãƒã‚¹ã‚¯ã€ï¼ˆ0ã€œ1ï¼‰ã‚’å‡ºåŠ›

```
ç”»åƒ â†’ FFT â†’ å‘¨æ³¢æ•°çµ±è¨ˆé‡ï¼ˆå¸¯åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ Ã— 8ï¼‰
             ï¼‹                              â†’ èåˆ â†’ æ”»æ’ƒå„ªå…ˆãƒã‚¹ã‚¯
ç”»åƒ â†’ MobileNetV3 â†’ ç”»åƒç‰¹å¾´é‡
```

---

#### âš¡ Stage 2: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«æ”»æ’ƒï¼ˆ`core/efficient_unmarker.py`ï¼‰

ç”»åƒã‚’æœ€é©åŒ–ã—ã¦é€ã‹ã—æ¤œå‡ºã‚¹ã‚³ã‚¢ã‚’ä¸‹ã’ã‚‹ã€ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­æ ¸éƒ¨åˆ†ã§ã™ã€‚

**æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—ï¼š**
```python
# Adam ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã§ä»¥ä¸‹ã®æå¤±ã‚’æœ€å°åŒ–
loss = w_det Ã— æ¤œå‡ºæå¤±          # é€ã‹ã—æ¤œå‡ºã‚¹ã‚³ã‚¢ã‚’ä¸‹ã’ã‚‹
     + w_freq Ã— å‘¨æ³¢æ•°æå¤±        # ç‰¹å®šå‘¨æ³¢æ•°æˆåˆ†ã‚’é™¤å»
     + w_smooth Ã— å¹³æ»‘åŒ–æå¤±      # ãƒã‚¤ã‚ºã‚’æŠ‘åˆ¶
     + w_rec Ã— é ˜åŸŸå†æ§‹æˆæå¤±     # ãƒã‚¹ã‚¯å†…ã®ç”»è³ªã‚’ä¿ã¤
     + w_bg Ã— èƒŒæ™¯ä¿æŒæå¤±        # ãƒã‚¹ã‚¯å¤–ã®ç”»è³ªã‚’ä¿ã¤
     + PSNR ãƒšãƒŠãƒ«ãƒ†ã‚£           # ç”»è³ªåŠ£åŒ–ã‚’é˜²ãã‚½ãƒ•ãƒˆåˆ¶ç´„
```

**ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å‡¦ç†ï¼š**
| ãƒ•ã‚§ãƒ¼ã‚º | è§£åƒåº¦ | åå¾©å›æ•° | ç›®çš„ |
|---|---|---|---|
| ä½è§£åƒåº¦æœ€é©åŒ– | 256Ã—256 | æœ€å¤§40å› | ç²—ãå¤§åŸŸçš„ãªé€ã‹ã—é™¤å» |
| ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ« | â†’ å…ƒã‚µã‚¤ã‚º | â€” | bicubic è£œé–“ |
| é«˜è§£åƒåº¦æœ€é©åŒ– | å…ƒã‚µã‚¤ã‚º | æœ€å¤§60å› | ç²¾å¯†ãªä»•ä¸Šã’ |

---

#### ğŸ›‘ æ—©æœŸåœæ­¢ï¼ˆ`core/early_stopping.py`ï¼‰

ç„¡é§„ãªè¨ˆç®—ã‚’çœããŸã‚ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ¡ä»¶ã§æœ€é©åŒ–ã‚’æ—©æœŸçµ‚äº†ã—ã¾ã™ï¼š

| åœæ­¢ç†ç”± | æ¡ä»¶ |
|---|---|
| `stopped_by_detection` | æ¤œå‡ºã‚¹ã‚³ã‚¢ãŒé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 0.5ï¼‰ã‚’ä¸‹å›ã£ãŸ |
| `stopped_by_convergence` | ç›´è¿‘5å›ã®æå¤±åˆ†æ•£ãŒ 1e-4 æœªæº€ï¼ˆåæŸã—ãŸï¼‰ |
| `stopped_by_quality` | PSNR ãŒä¸‹é™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 18.0 dBï¼‰ã‚’4å›é€£ç¶šä¸‹å›ã£ãŸ |

---

#### ğŸ–¼ï¸ ã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ï¼ˆ`core/inpainting_cnn.py`ï¼‰

Partial Convolution ãƒ™ãƒ¼ã‚¹ã® U-Net ã§ã€ãƒã‚¹ã‚¯é ˜åŸŸã‚’è‡ªç„¶ã«è£œå®Œã—ã¾ã™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚

```
å…¥åŠ›: RGBç”»åƒ(3ch) + ãƒã‚¹ã‚¯(1ch) = 4ch
      â†“ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆPartial Conv Ã— 5æ®µ: 64â†’128â†’256â†’512â†’512ï¼‰
      â†“ ãƒ‡ã‚³ãƒ¼ãƒ€ï¼ˆUpsample + Skip Connection Ã— 5æ®µï¼‰
      â†“ æœ€çµ‚Conv + Tanh â†’ [0,1] ã«ã‚¹ã‚±ãƒ¼ãƒ«
å‡ºåŠ›: è£œå®Œã•ã‚ŒãŸ RGB ç”»åƒ(3ch)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:** ç´„ 14.3Mï¼ˆ256Ã—256 è§£åƒåº¦æ™‚ï¼‰

---

#### ğŸ“ è©•ä¾¡æŒ‡æ¨™ï¼ˆ`utils/metrics.py`ï¼‰

| æŒ‡æ¨™ | èª¬æ˜ |
|---|---|
| **PSNR** (Peak Signal-to-Noise Ratio) | ç”»è³ªã®å®¢è¦³è©•ä¾¡ã€‚å€¤ãŒé«˜ã„ã»ã©åŸç”»ã«è¿‘ã„ï¼ˆç›®æ¨™: 23 dB ä»¥ä¸Šï¼‰ |
| **SSIM** (Structural Similarity) | äººé–“ã®è¦–è¦šç‰¹æ€§ã«åŸºã¥ãé¡ä¼¼åº¦ï¼ˆ0ã€œ1ã€1ãŒå®Œå…¨ä¸€è‡´ï¼‰ |
| **Masked PSNR/SSIM** | ãƒã‚¹ã‚¯é ˜åŸŸå†…ã ã‘ã®è©•ä¾¡æŒ‡æ¨™ |

---

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`configs/fast_cnn_only.yaml`ï¼‰

```yaml
device: cuda                # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ï¼ˆcuda / cpuï¼‰
target_detection: 0.5       # ã“ã®å€¤ã‚’ä¸‹å›ã‚Œã°ã€Œé™¤å»æˆåŠŸã€ã¨åˆ¤å®š
max_iterations: 120         # æœ€å¤§åå¾©å›æ•°

detector:
  mode: quick               # æ¤œå‡ºå™¨ãƒ¢ãƒ¼ãƒ‰ï¼ˆquick=QuickDetector (MobileNetV3-Small) ã®ã¿ï¼‰

stage1:
  enabled: true             # å‘¨æ³¢æ•°è§£æã‚’ä½¿ã†

stage2:
  low_res_size: 256         # ä½è§£åƒåº¦ãƒ•ã‚§ãƒ¼ã‚ºã®ã‚µã‚¤ã‚º
  low_iters: 40             # ä½è§£åƒåº¦ã§ã®æœ€å¤§åå¾©æ•°
  high_iters: 60            # é«˜è§£åƒåº¦ã§ã®æœ€å¤§åå¾©æ•°

stage3:
  enabled: false            # å“è³ªæ”¹å–„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç„¡åŠ¹ãƒ»é€Ÿåº¦é‡è¦–ï¼‰

stopping:
  psnr_min: 18.0            # PSNR ã®ä¸‹é™ï¼ˆdBï¼‰
  psnr_patience: 4          # ä¸‹é™ã‚’ä½•å›é€£ç¶šã§ä¸‹å›ã£ãŸã‚‰åœæ­¢ã™ã‚‹ã‹

loss:
  detector_weight: 1.0      # æ¤œå‡ºæå¤±ã®é‡ã¿
  psnr_penalty: 0.1         # PSNR ãƒšãƒŠãƒ«ãƒ†ã‚£ã®å¼·ã•
  psnr_penalty_floor: 18.0  # PSNR ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ç™ºå‹•ã™ã‚‹ä¸‹é™
```

---

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
CNN-only-EfficientUnMarker/
â”œâ”€â”€ core/                          # ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
â”‚   â”œâ”€â”€ efficient_unmarker.py      # EfficientUnMarker ã‚¯ãƒ©ã‚¹ï¼ˆå…¨ä½“åˆ¶å¾¡ï¼‰
â”‚   â”œâ”€â”€ detection.py               # ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯æ¤œå‡ºå™¨ï¼ˆMobileNetV3, DenseNetï¼‰
â”‚   â”œâ”€â”€ stage1_frequency.py        # å‘¨æ³¢æ•°è§£æãƒ»å¸¯åŸŸãƒã‚¹ã‚¯äºˆæ¸¬
â”‚   â”œâ”€â”€ inpainting_cnn.py          # Partial Conv U-Netï¼ˆã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ï¼‰
â”‚   â””â”€â”€ early_stopping.py          # æ—©æœŸåœæ­¢ãƒ»é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼
â”œâ”€â”€ utils/                         # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚   â”œâ”€â”€ image_processing.py        # FFT å¤‰æ›ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒ»ãƒªã‚µã‚¤ã‚º
â”‚   â”œâ”€â”€ metrics.py                 # PSNR / SSIM è¨ˆç®—
â”‚   â”œâ”€â”€ losses.py                  # æå¤±é–¢æ•°
â”‚   â””â”€â”€ masks.py                   # ãƒã‚¹ã‚¯ç”Ÿæˆãƒ»å‡¦ç†
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ fast_cnn_only.yaml         # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ benchmark_cnn_only.py      # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ datasets/                      # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç½®ãå ´ï¼ˆè¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
â”œâ”€â”€ results/                       # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ CSV ã®å‡ºåŠ›å…ˆ
â”œâ”€â”€ requirements.txt               # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸€è¦§
â””â”€â”€ install.sh                     # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

---

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ä½¿ã„æ–¹

#### 1. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

ã¾ãŸã¯:

```bash
bash install.sh
```

RTX 5070 Ti ãªã© sm_120 ç³» GPU ã®å ´åˆã¯ CUDA 12.8 å¯¾å¿œ PyTorch ãŒå¿…è¦ã§ã™:

```bash
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128
```

#### 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ï¼ˆä»»æ„ï¼‰

[Kaggle - Large-scale Common Watermark Dataset](https://www.kaggle.com/datasets/kamino/largescale-common-watermark-dataset) ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ `datasets/` ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚

#### 3. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œ

```bash
python experiments/benchmark_cnn_only.py \
  --config configs/fast_cnn_only.yaml \
  --input_dir <é€ã‹ã—å…¥ã‚Šç”»åƒãƒ•ã‚©ãƒ«ãƒ€> \
  --clean_dir <ã‚¯ãƒªãƒ¼ãƒ³ç”»åƒãƒ•ã‚©ãƒ«ãƒ€> \
  --wm_suffix v2 \
  --output results/benchmarks/phaseA_cnn_only.csv
```

**ä¸»ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼š**

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ |
|---|---|
| `--config` | YAML è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ |
| `--input_dir` | é€ã‹ã—å…¥ã‚Šç”»åƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª |
| `--clean_dir` | æ¯”è¼ƒç”¨ã‚¯ãƒªãƒ¼ãƒ³ç”»åƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆPSNRè¨ˆç®—ã«ä½¿ç”¨ï¼‰ |
| `--wm_suffix` | é€ã‹ã—å…¥ã‚Šãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾è­˜åˆ¥å­ï¼ˆä¾‹: `v2` â†’ `xxxv2.jpg` ã‚’å‡¦ç†ï¼‰ |
| `--output` | çµæœ CSV ã®å‡ºåŠ›ãƒ‘ã‚¹ |
| `--det_threshold` | æ¤œå‡ºæˆåŠŸé–¾å€¤ã®ä¸Šæ›¸ã |

çµæœã¯ `results/benchmarks/` ä»¥ä¸‹ã« CSV å½¢å¼ã§ä¿å­˜ã•ã‚Œã¾ã™ã€‚

---

### å‚è€ƒæ€§èƒ½ï¼ˆ44 æšã®å®Ÿç”»åƒã§æ¸¬å®šï¼‰

| æŒ‡æ¨™ | å€¤ | ç›®æ¨™ |
|---|---|---|
| æˆåŠŸç‡ | **95.5%** | > 90% |
| å¹³å‡å‡¦ç†æ™‚é–“ | **1.5 ç§’/æš** | < 10 ç§’ |
| ãƒ”ãƒ¼ã‚¯ VRAM | **0.26 GB** | < 8 GB |
| å¹³å‡ PSNR | **23.5 dB** | > 20 dB |

> â€» ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯ã®ç¨®é¡ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»GPU ã«ã‚ˆã£ã¦çµæœã¯ç•°ãªã‚Šã¾ã™ã€‚

---

### å‚è€ƒæ–‡çŒ®ãƒ»ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ

- **å…ƒã® UnMarker è«–æ–‡ãƒ»ã‚³ãƒ¼ãƒ‰:**  
  UnMarker: A Universal Attack on Defensive Image Watermarking  
  <https://github.com/andrekassis/ai-watermark>

- **ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:**  
  Large-scale Common Watermark Dataset  
  <https://www.kaggle.com/datasets/kamino/largescale-common-watermark-dataset>

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ç ”ç©¶ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç›®çš„ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚  
å•†ç”¨åˆ©ç”¨ã‚„å¤§è¦æ¨¡ä½¿ç”¨ã®éš›ã¯ã€ä¸Šè¨˜ã‚ªãƒªã‚¸ãƒŠãƒ« UnMarker ã®ç ”ç©¶ã‚’å‚ç…§ãƒ»ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã—ã¦ãã ã•ã„ã€‚

---

## English

<a name="english"></a>

A fast, lightweight, and practical watermark removal pipeline using only a CNN-based detector (MobileNetV3).  
This repository provides a minimal, reproducible baseline for universal watermark removal with a focus on speed, memory efficiency, and simplicity.

### Overview

- **Purpose:** Remove visible watermarks using a 3-stage pipeline (frequency analysis â†’ multi-scale attack â†’ quality safeguard) guided only by a CNN-based detector.
- **Target hardware:** RTX 5070 Tiâ€“class GPU or similar.
- **Design goals:** <10s per image, <8GB VRAM, >90% removal success.
- **Relation to EfficientUnMarker:** Distilled version of the full EfficientUnMarker project, containing only the CNN-based (MobileNetV3) detection and attack components.

### Pipeline Architecture

```
Watermarked Image
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Frequency Analysis        â”‚
â”‚  torch.fft spectrum analysis        â”‚
â”‚  â†’ Generate frequency band mask     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ band mask
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: Multi-scale Attack        â”‚
â”‚  Optimize at 256Ã—256 (coarse)       â”‚
â”‚  â†’ Upsample to original resolution  â”‚
â”‚  â†’ Fine-tune at full resolution     â”‚
â”‚  (with early stopping & PSNR guard) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ attacked image
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: Quality Refinement        â”‚
â”‚  (optional, disabled by default)    â”‚
â”‚  Adaptive low-pass filter           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      Output Image (watermark removed)
```

### Features

- **Stage 1 â€“ Frequency analysis:** `torch.fft`-based spectrum analysis + MobileNetV3 features to generate a frequency band mask.
- **Stage 2 â€“ Multi-scale attack:** 256â†’original resolution optimization with early stopping and a soft PSNR penalty to avoid excessive degradation.
- **Stage 3 â€“ Optional refinement:** Additional quality refinement stage (disabled by default in this baseline).
- **Dual-branch detector:** MobileNetV3 (quick) + DenseNet-121 (deep), with adaptive switching based on detection confidence.
- **Metrics:** Success flag, detection score, PSNR, SSIM, runtime, and peak VRAM usage.
- **Configurable:** YAML-based configuration for attack hyperparameters and stopping criteria.

### Dataset

Evaluation uses the **Large-scale Common Watermark Dataset**:

- Source: [Kaggle - Large-scale Common Watermark Dataset](https://www.kaggle.com/datasets/kamino/largescale-common-watermark-dataset)
- Contains realistic visible watermarks for benchmarking removal algorithms.

### Quick Start

#### Install dependencies

```bash
pip install -r requirements.txt
```

#### Download dataset (optional)

Download the Large-scale Common Watermark Dataset from the link above and place it in `datasets/`.

#### Run benchmark (example)

```bash
python experiments/benchmark_cnn_only.py \
  --config configs/fast_cnn_only.yaml \
  --input_dir <watermarked_dir> \
  --clean_dir <clean_dir> \
  --wm_suffix v2 \
  --output results/benchmarks/phaseA_cnn_only.csv
```

- `--wm_suffix v2` matches files like `xxxv2.jpg` (watermarked) to `xxx.jpg` (clean).

#### Results

- Per-image metrics and aggregates are saved under `results/benchmarks/`.

### Directory Structure

```
core/
â”œâ”€â”€ efficient_unmarker.py   # Main EfficientUnMarker class (pipeline controller)
â”œâ”€â”€ detection.py            # Watermark detectors (MobileNetV3, DenseNet-121)
â”œâ”€â”€ stage1_frequency.py     # Frequency analysis & band mask prediction
â”œâ”€â”€ inpainting_cnn.py       # Partial Conv U-Net for inpainting (optional)
â””â”€â”€ early_stopping.py       # Early stopping & progress tracking
utils/
â”œâ”€â”€ image_processing.py     # FFT transforms, filters, multi-scale resize
â”œâ”€â”€ metrics.py              # PSNR / SSIM computation
â”œâ”€â”€ losses.py               # Loss functions
â””â”€â”€ masks.py                # Mask generation and processing
configs/
â””â”€â”€ fast_cnn_only.yaml      # YAML config (hyperparameters)
experiments/
â””â”€â”€ benchmark_cnn_only.py   # Benchmark & evaluation script
datasets/                   # Place downloaded datasets here
requirements.txt
```

### Reference Performance

Measured on 44 real images from the Large-scale Common Watermark Dataset:

| Metric | Value | Target |
|---|---|---|
| Success rate | **95.5%** | > 90% |
| Avg runtime | **1.5 s / image** | < 10 s |
| Peak VRAM | **0.26 GB** | < 8 GB |
| Avg PSNR | **23.5 dB** | > 20 dB |

(Results may vary depending on watermark scheme, dataset, and GPU.)

### License / Attribution

This repository is intended for research and benchmarking.  
For commercial or large-scale use, please refer to and credit the original UnMarker work:

- UnMarker: A Universal Attack on Defensive Image Watermarking  
  <https://github.com/andrekassis/ai-watermark>

Dataset credit:
- Large-scale Common Watermark Dataset
  <https://www.kaggle.com/datasets/kamino/largescale-common-watermark-dataset>
